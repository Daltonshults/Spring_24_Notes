### Article: Autonomous Vehicles Are Driving Blind
* Article Information:
	* Author: Julia Angwin
	* Date: October, 11th 2023
	* Opinion Piece
* From Linked Source: "A woman suffered "traumatic injuries" after being hit by a human driver and becoming trapped under a Cruise Robotaxi in Downtown San Francisco Monday night, according to a Cruise spokesperson."
	* Not a common occurrence: How can we design training environments to handle these unexpected situations? Is there any way to avoid the unexpected when designing agents?
* No federal safety regulations when it comes to testing the software of autonomous vehicles
	* Do you think regulations like these would hurt or help the AI industry as a whole?
		* Do you think a set of standards should be in place for autonomous vehicles? And how do you think that these standards could change the advancement of these technologies?
	* Currently relying on self-regulation and testing.
	* Seems that they crash and cause much less property damage according the Waymo's research, but anecdotal evidence points towards incidents where self-driving cars end up doing more damage than a regular vehicle would.
		* Blocking emergency vehicles
	* How do you think that people's perspectives on AI in general effect how they view AI advancements in general? Do you think media has increased the hostility towards AI systems, and are causing people to overlook the damage that is currently occurring because of these systems? **Does peoples fear of AI cause them to misunderstand, and regulate the technology improperly?**
		* Example: Congress banning AI systems from making nuclear launch decisions
	* **How has the public's perception of AI and these technologies changed the way we regulate them? Do you think our current approaches are reasonable? Do we need more or less regulation around the industry?**

### Article: What Self-Driving Cars Tell Us About AI Risks
* Article Information: 
	* Author: Mary L. Cummings
	* Date: July, 30th 2023
* Since 2016: 25 deaths, hundreds of injuries, and property damage
* Human errors in operation get replaced by human errors in coding
* AI Failure modes are hard to predict
	* Self-driven cars see about twice the rate of read-end collisions as do cars driven by people
* Probabilistic estimates do not approximate judgement under uncertainty
	* These systems don't compensate for when they have lack of information
		* Have no way to assess whether their estimates were accurate enough to take an action
	* AI models do poorly in environments where their training data did not account for
		* Drove through firefighters actively fighting a fire
		* Drove over downed power lines
* Maintaining AI is just as important as creating AI
	* How would you account for something like Model Drift in self-driving cars, or other automated machines?
		* How can we adjust training to keep up with real world developments? New types of cars, other driving systems, round-a-bouts, or other traffic inventions?
* Do you think a set of standards should be in place for autonomous vehicles? And how do you think that these standards could change the advancement of these technologies?