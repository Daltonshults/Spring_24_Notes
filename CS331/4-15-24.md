### Search Algorithms
* These algorithms create a path to discover their answers
* Problems from last week:
	* Fully observable
	* Known environment
	* Know the results of our actions
* Local Search:
	* Simpler
	* Uses less memory
	* Have drawbacks
		* Complete
		* Optimality
	* Solution: The state that we end up in the end, and do not care about what the path is
* Local Search: Useful when the path is not important
	* Constraints: Don't know what the goal states are
		* Want to maximize/minimize a cost or objective function
			* Don't know if it is the highest or lowest, but it is a goal state
		* Don't start at a specific state and searching for the goal state from there, but instead can start anywhere
	* Parts:
		* One action at a time
		* Can only reevaluate the objective function from the current state
		* Environment: Still fully observable, and know what our actions do
			* Large Environment: Means we have a ton or infinite states
		* Can save space complexity
		* Real world problems often have infinite states and you can't model an infinite state space
	* Commonly used for optimization problems
		* Return the best state according to an objective function 
		* If the state space is infinite you can get close to the best answer, but not the best one
	* Problem: Doesn't fit the task environment because they have no set of goal states that are easily definable
		* No path cost
	* State Space Landscape: Represented as a 2d graph.
		* X axis is the state
		* Y axis is the performance metric
		* Can use the state-space landscape to figure out the state that we want to be in
			* Can only move left or right
				* $x-1$ or $x+1$ 
			* Does help improve the state to where you are
				* Can modify this to make sure it attempts to reach the global maximum
		* **Greedy Algorithm** Looking at all of the neighboring states, and check the one that is going to get us closest to the top
### Hill Climbing:
* A greedy algorithm that checks the neighboring states, and if they are higher you go to them. If there are no neighbors that are higher than you then you return that state
* The direction you decide to go has a massive effect on where you will end up
	* Solution: 

### 8 Queens Problem
* 8 X 8 chessboard
* Place them on the board so that no queen can attack each other
* States that we will consider
	* All 8 queens are placed
		* **Only checking complete states:** No state where < 8 queens are placed
* Measure this with the number of pairs of queens that can attack each other

$$
{n \choose t } = \frac{n!}{k!(k-n)}
$$
*  Restrict our actions to actions that don't hurt our state
* We have 56 actions because there are 7x8 spaces that we can move into
* Hill climbing can be used to solve this problem
* Three Queens: There is no solution, but we can get the objective function to a minimum
	* Ranges from 1-3
* Five Queens: Has a solution, but only a limited number of goal states



| Q   | Q   | Q   | Q   | Q   |
| --- | --- | --- | --- | --- |
|     |     |     |     |     |
|     |     |     |     |     |
|     |     |     |     |     |
|     |     |     |     |     |

|     |     | Q   | Q   | Q   |
| --- | --- | --- | --- | --- |
| Q   |     |     |     |     |
|     |     |     |     |     |
|     |     |     |     |     |
|     | Q   |     |     |     |

|     |     |     | Q   | Q   |
| --- | --- | --- | --- | --- |
| Q   |     |     |     |     |
|     |     | Q   |     |     |
|     |     |     |     |     |
|     | Q   |     |     |     |

|     |     |     | Q   | Q   |
| --- | --- | --- | --- | --- |
| Q   |     |     |     |     |
|     |     | Q   |     |     |
|     |     |     |     |     |
|     | Q   |     |     |     |
Example 2:

| Q   | Q   | Q   | Q   | Q   |
| --- | --- | --- | --- | --- |
|     |     |     |     |     |
|     |     |     |     |     |
|     |     |     |     |     |
|     |     |     |     |     |

| Q   | Q   |     | Q   | Q   |
| --- | --- | --- | --- | --- |
|     |     |     |     |     |
|     |     |     |     |     |
|     |     | Q   |     |     |
|     |     |     |     |     |

| Q   | Q   |     |     | Q   |
| --- | --- | --- | --- | --- |
|     |     |     | Q   |     |
|     |     |     |     |     |
|     |     | Q   |     |     |
|     |     |     |     |     |

|     | Q   |     |     |     |
| --- | --- | --- | --- | --- |
|     |     |     | Q   |     |
| Q   |     |     |     |     |
|     |     | Q   |     |     |
|     |     |     |     | Q   |

### Side Stepping:
* What do you do when the states next to you lead to the same return of the objective function
* Could side step forever: Could go the wrong direction and never find the global max/min because you check the wrong direction FOREVER
* 8 Queens: With hill climbing has a 15-16% chance of finding the right solution
* Sidestepping occurs across plateau
	* Helps with plateaus but does not work on disconnected objective functions

### First Choice Hill Climbing (Stochastic)
* Works well in a infinite state space
* Can't possibly look at all of the states and pick the best one
* Instead, we generate states until we find one that "goes uphill"
* Allows infinite state space search
* Not always optimal

### Random Restart Hill Climbing:
* Know the objective function isn't maximize
* Once we get to a maximum we are going to randomly choose a start state until we find a global maximum, or the maximum that is the highest that we discover
* Will find an optimal solution based on the probability of finding a solution
	* 8 Queens:
		* Failure will cost 3 steps
		* Success will cost 4 steps
	* $6*3+(1+4)$
	* $\frac{1-p}{p}\times c(f) + c(s)$ 
		* p is the probability of success
		* c(f) cost of failure
		* s(f) cost of success
* Using side stepping it only increases the number of times we need to find a solution by 3 in the case of 8 queens
* Can be at worse $B^d$ but in practice it is much less
* Random Restart: Can be complete if ran enough times
* Random Walk: Will be complete because eventually you will land on the state
	* Can take more than exponential time
	* Can run in a cycle infinitely 
	* Don't always choose to go up, and because of this it can break out of local mins/max

A * : Use the straight line distance between the coordinates to solve this

#LocalSearch #HillClimbing #FirstChoiceHillClimbing
