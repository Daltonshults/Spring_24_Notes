### Propositional Logic
* Anything can be represented with ors, negation, and conjunctions
* 3-Sat problem: $(A \land B \lor C) \land (\neg A \lor B \lor C)$
* Knowledge bases are made up of sentences that are facts
	* A conjunction of sentences
	* This is the same as what we have in propositional logic
	* $(A \land B \lor C) \land (\neg A \lor B \lor C) \land (...) \land (...)$
*  Conjunctive normal form is useful because we can break it down 

Conjunctive Normal Form (CNF): 
* we also have $\leftrightarrow$

Steps:
1. Get rid of the bi-conditional $A\leftrightarrow B$ 
	1. Breaking down the complicated into the more simple things
2. $A \Rightarrow B \land B \Rightarrow A$ Get rid of implications
	1. $(\neg A \lor B) \land (\neg B \lor A)$ 
3. Repeatedly move negations forward
	1. $\neg (\neg A) = A$
	2. $\neg(A \lor B) \equiv (\neg A \land \neg B)$
	3.  $\neg(A \land B) \equiv (\neg A \lor \neg B)$
	4. $\neg(\neg A \lor \neg (B \lor C))$
	5. $(A \lor \neg (\neg B \land \neg C))$
	6. $A \land (B \lor C)$
4. Distribute all of the ands over conjunctions
	1. $(A \lor B) \land (A \lor C)$
![[Pasted image 20240506085116.png]]

Having only one clause being true can be easier for resolution
#### Conjunctive Normal Form
* $( (A) \land (B) \land (C) ) \equiv (A \lor A) \land (B \lor B) \land (C \lor C)$

### Resolution Algorithm 
```Algo
PL-Resolution( KB, Alpha) -> True or False: entails alpha or not
	set clauses <- CNF(KB and !alpha) // Implies that both can be true
	set new_clauses <- {}
repeats:
	for each pair of clauses C_i C_j in clauses
		resolvants <- PL-Resolve(C_i, C_j) // No duplicate literals 
										   // Returns unresolved disjunction
		if {} in resolvants: -> True // if we can resolve two sentences down to
									 // nothing, a tautology, the knowledge base
									 // entails alpha
			new <- new Union resolvants
	if new is a subset of C clauses
		return False
	else 
		clauses <- clauses Union new
```
### Probabilities and Uncertainties
* Random Variable $X$
	* Define a domain, and a range of values that it can take
	* Each value is associated with some level of certainty 
	* Coin Flip : 0.5 T and 0.5 F
		* Can represent a lot of stuff as booleans even if it isn't true or false
	* KevinLate:
		* T: 0.95
		* F: 0.05
	* CardSuit: Discrete variable, some number greater than two
		* spades 0.25
		* diamonds 0.25
		* hearts 0.25
		* clubs 0.25
* Discrete Random Variables are mutually exclusive
	* Exhaustive: Meaning that the probability of $P(A = v_i) \lor v A = v_j \lor A = v_k) = 1$
	*  Mutual Exclusivity: The probability of $(A=v_i \land A=v_j) = 0$
		* Can't be two values at the same time
	* Example dice rolls: prior probabilities
		*  $P(A) \equiv P(A=true)$
		* $P(total = 11) = \frac{1}{18}$
		* $P(doubles) = \frac{1}{6}$
	* As we are rolling the dice we get more information
		* $P(total = 11) \  \ if \  \ after \  \ second \  \ roll \  \ changes$
			* This is just like sports betting
	* How we write these:
		* Conditional//Posteriors
		* $P(total = 11 | die = 5)$ 
			* the probability of rolling an 11 if the first dice is 5
* Calculating these 
	* $P(a | b) = \frac{P(a \land b)}{P(b)}$
	* $P(doubles | die=5) = \  \ \frac{P(double) \land die=5}{P(die=5)}$
	* $= \frac{\frac{1}{36}}{\frac{1}{6}} = \frac{1}{6}$
	* You can't always cancel the top value because the probabilities could be waited
* $P(a \land b) = P(a|b)P(b)$
	* in order for a and b to be true, first b is true, and a given b is true
* Two axioms of probability
	* $0 <= P(a) <= 1| \forall a \in U$$
	* $\sum P(a) = 1$
* Contributive
	* $P(a \lor b) = P(a) + P(b) - P(a \land b)$
	* $P(\neg a) = 1-P(a)$
* $P(a, b)$ 
	* b = coin toss
	* a = card

|          | Heads | Tails | Total |
| -------- | ----- | ----- | ----- |
| Spades   | 0.125 | 0.125 | 0.25  |
| Hearts   | 0.125 | 0.125 | 0.25  |
| Clubs    | 0.125 | 0.125 | 0.25  |
| Diamonds | 0.125 | 0.125 | 0.25  |
| Total    | 0.5   | 0.5   | 1.0   |
* If the table gets too large we cannot save the entire table, and will cost exponential time or space to keep track of the probability distribution
